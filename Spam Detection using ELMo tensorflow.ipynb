{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from tensorflow.python import keras\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = \"https://tfhub.dev/google/elmo/2\"\n",
    "embed = hub.Module(url)\n",
    "\n",
    "data = pd.read_csv('/Users/wenjunshi/Desktop/spam.csv', encoding='latin-1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LabelEncoder()"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y = list(data['v1'])\n",
    "x = list(data['v2'])\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "le.fit(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1. 0.]\n",
      " [0. 1.]\n",
      " [1. 0.]\n",
      " [1. 0.]]\n"
     ]
    }
   ],
   "source": [
    "def encode(le, labels):\n",
    "    enc = le.transform(labels)\n",
    "    return keras.utils.to_categorical(enc)\n",
    "\n",
    "def decode(le, one_hot):\n",
    "    dec = np.argmax(one_hot, axis=1)\n",
    "    return le.inverse_transform(dec)\n",
    "test = encode(le, ['ham', 'spam', 'ham', 'ham'])\n",
    "print(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5572\n"
     ]
    }
   ],
   "source": [
    "test = encode(le, ['ham', 'spam', 'ham', 'ham'])\n",
    "\n",
    "untest = decode(le, test)\n",
    "\n",
    "x_enc = x\n",
    "y_enc = encode(le, y)\n",
    "\n",
    "x_train = np.asarray(x_enc[:5000])\n",
    "y_train = np.asarray(y_enc[:5000])\n",
    "\n",
    "x_test = np.asarray(x_enc[5000:])\n",
    "y_test = np.asarray(y_enc[5000:])\n",
    "print(len(y_enc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Input, Lambda, Dense\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras import backend as K\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I1022 13:15:13.807011 4605568448 tf_logging.py:115] Saver not created because there are no variables in the graph to restore\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1\n",
      "5000/5000 [==============================] - 1276s 255ms/step - loss: 0.0910 - acc: 0.9712\n"
     ]
    }
   ],
   "source": [
    "def ELMoEmbedding(x):\n",
    "    return embed(tf.squeeze(tf.cast(x, tf.string)), signature=\"default\", as_dict=True)[\"default\"]\n",
    "\n",
    "input_text = Input(shape=(1,), dtype=tf.string)\n",
    "embedding = Lambda(ELMoEmbedding, output_shape=(1024, ))(input_text)\n",
    "dense = Dense(256, activation='relu')(embedding)\n",
    "pred = Dense(2, activation='softmax')(dense)\n",
    "model = Model(inputs=[input_text], outputs=pred)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())  \n",
    "    session.run(tf.tables_initializer())\n",
    "    history = model.fit(x_train, y_train, epochs=1, batch_size=32)\n",
    "    model.save_weights('./elmo-model.h5')\n",
    "\n",
    "with tf.Session() as session:\n",
    "    K.set_session(session)\n",
    "    session.run(tf.global_variables_initializer())\n",
    "    session.run(tf.tables_initializer())\n",
    "    model.load_weights('./elmo-model.h5')  \n",
    "    predicts = model.predict(x_test, batch_size=32)\n",
    "\n",
    "y_test = decode(le, y_test)\n",
    "y_preds = decode(le, predicts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[497   1]\n",
      " [ 11  63]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.98      1.00      0.99       498\n",
      "        spam       0.98      0.85      0.91        74\n",
      "\n",
      "    accuracy                           0.98       572\n",
      "   macro avg       0.98      0.92      0.95       572\n",
      "weighted avg       0.98      0.98      0.98       572\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "\n",
    "print(metrics.confusion_matrix(y_test, y_preds))\n",
    "\n",
    "print(metrics.classification_report(y_test, y_preds))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ML",
   "language": "python",
   "name": "ml"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
